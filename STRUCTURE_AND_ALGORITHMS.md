# Структура и алгоритмы работы

Документ описывает текущую архитектуру, алгоритмы сопоставления, поток данных, подключение Ollama и способ запуска сервиса.

## 1) Общая структура проекта

```
app/
  api/
    routes.py          # REST API эндпоинты
  core/
    config.py          # конфигурация из .env
    logging.py         # логирование
  db/
    schema.sql         # схема БД
    session.py         # подключение к БД
  models/
    schemas.py         # Pydantic-схемы
  repositories/
    items.py           # SQL-запросы
  services/
    estimation.py      # логика расчёта и агрегирования
    matching.py        # ранжирование и fuzzy
    ollama.py          # форматирование отчёта
  utils/
    normalization.py   # нормализация строк
main.py                # инициализация FastAPI
```

## 2) Диаграмма потока данных

```
Пользователь
   |
   v
[POST /v1/estimate]
   |
   v
API (FastAPI)  -->  Normalization  -->  Поиск в БД
   |                                |      |
   |                                |      v
   |                                |   exact / fuzzy
   |                                |
   |                                v
   |                          Агрегация времени
   |
   v
(опционально) Ollama -> Форматирование отчёта
   |
   v
JSON-ответ пользователю
```

## 3) Логика связей и повторяемость

- Один проект содержит много шкафов.
- Один шкаф содержит много позиций (наименований и уникальных артикулов).
- Каждое наименование связано с **видом номенклатуры**.
- Виды номенклатуры связаны с **этапами**.
- Этапов всего ~10, видов номенклатуры ~400, но они **повторяются** между шкафами и позициями.
- Артикул считается уникальным ключом, наименования часто повторяются.

## 4) Как сейчас работает алгоритм

1. **Нормализация входа**
   - приводим к нижнему регистру
   - удаляем лишние символы
   - заменяем `ё` → `е`

2. **Точный поиск**
   - ищем совпадения по `items.name_norm` или `LOWER(items.name)`

3. **Нечёткий поиск (если точного нет)**
   - если включен `USE_PG_TRGM=true`, берём кандидатов из PostgreSQL через `pg_trgm`
   - иначе — простая выборка по токенам
   - далее `rapidfuzz.WRatio` для расчёта похожести
   - отбираем кандидатов с `score >= FUZZY_MIN_SCORE`

4. **Агрегация времени**
   - для найденных строк поднимаем связи через JOIN:
     `items -> nomenclature_types -> stages`
   - суммируем `assembly_time_minutes` по шкафам и проектам

5. **Формирование отчёта (опционально)**
   - если `format_report=true` и `ENABLE_LLM=true`, данные отправляются в Ollama
   - модель формирует итоговый читаемый отчёт

## 5) Откуда берутся данные и куда уходят

**Источники:**
- пользовательские строки наименований
- база данных PostgreSQL

**Куда уходят:**
- JSON-ответ через REST API
- при включении LLM — отправка данных в локальную Ollama

## 6) Какая модель Ollama используется

По умолчанию в `.env.example` задана модель:

```
OLLAMA_MODEL=qwen2.5:3b
```

Это лёгкая модель, подходящая для локального запуска без GPU. Её задача — только оформить итоговый отчёт, а не выполнять поиск.

## 7) Когда подключается Ollama

Подключение происходит **только после** завершения основного поиска и расчёта, при соблюдении двух условий:
- в запросе `format_report=true`
- в конфигурации `ENABLE_LLM=true`

В противном случае API возвращает только JSON с результатами.

## 8) Интерфейс

Используется **REST API** на FastAPI.

Основной эндпоинт:
```
POST /v1/estimate
```

Интерактивный чат:
```
POST /v1/chat
```
Чат принимает сообщение пользователя, список наименований и историю диалога,
после чего возвращает готовый человекочитаемый ответ и сырые данные расчёта.
Пример запроса:
```
{
  "names": ["Щит вводной 3ф 25А", "Шкаф управления насосом"],
  "format_report": true,
  "project_code": "проект123",
  "cabinet_code": "шкаф111"
}
```

Пример запроса для чата:
```
{
  "message": "Посчитай время на сборку",
  "names": ["Щит вводной 3ф 25А", "Шкаф управления насосом"],
  "history": [],
  "project_code": "проект123",
  "cabinet_code": "шкаф111",
  "mode": "auto"
}
```
`mode` управляет режимом работы:
- `auto` — поиск только если переданы `names`
- `chat` — всегда только диалог, без поиска
- `estimate` — всегда поиск и расчет (даже если `names` пусты)

Пример ответа:
```
{
  "found_items": [...],
  "not_found_items": [...],
  "total_time_by_cabinet": {"шкаф111": 120},
  "total_time_by_project": {"проект123": 240},
  "report": "..."
}
```

## 9) Как запускать

1) Установка зависимостей:
```
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

2) Применить схему БД:
```
psql -d assembly -f app/db/schema.sql
```

3) Импорт CSV (пример):
```
python scripts/import_csv.py --path "Маленький пример большой таблицы .csv" --stage-times stage_times.json --default-time 0
```
`stage_times.json` — словарь вида `{ "Сборка корпуса": 30, "Дополнительные работы": 10 }`.
Если в CSV есть столбец `Шаблон врмени в минутах`, он имеет приоритет над JSON и `default-time`,
и сохраняется **в каждой позиции** (`items.assembly_time_minutes`).
Можно включить контроль импорта и отчет об ошибках:
```
python scripts/import_csv.py --path "Маленький пример большой таблицы .csv" --error-report import_errors.csv --strict
```
Отдельная статистика импорта:
```
python scripts/import_csv.py --path "Маленький пример большой таблицы .csv" --stats-out import_stats.json
```

4) Настроить `.env`:
```
cp .env.example .env
```

5) Запуск API:
```
uvicorn app.main:app --host 127.0.0.1 --port 8000
```

5) Убедиться, что Ollama запущен локально:
```
ollama pull qwen2.5:3b
ollama serve
```

## 10) Инкрементальный импорт

Для добавления только новых позиций без обновления существующих:
```
python scripts/import_csv.py --path "данные.csv" --incremental
```
Скрипт загрузит список артикулов из БД и пропустит дубликаты.

## 11) Примечания
- Для быстрого fuzzy-поиска желательно использовать PostgreSQL с расширением `pg_trgm`.
- При загрузке данных обязательно заполняйте `items.name_norm` нормализованной строкой.
- ИИ не ищет данные, он только форматирует результат.
